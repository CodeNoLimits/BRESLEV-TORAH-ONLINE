import google.generativeai as genai
import chromadb
from chromadb.utils import embedding_functions
import os
from typing import Dict, List, Optional
import json
import hashlib
import asyncio
from pathlib import Path

class GeminiContextManager:
    """Gestionnaire de contexte intelligent pour Gemini 1.5 Pro"""
    
    def __init__(self):
        # Configuration Gemini
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY non trouv√© dans les variables d'environnement")
        
        genai.configure(api_key=api_key)
        
        # Gemini 1.5 Pro avec 2M tokens!
        self.model = genai.GenerativeModel('gemini-1.5-pro-latest')
        self.flash_model = genai.GenerativeModel('gemini-1.5-flash')
        
        # ChromaDB pour recherche vectorielle
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        self.embedding_fn = embedding_functions.GoogleGenerativeAiEmbeddingFunction(
            api_key=api_key,
            model_name="models/text-embedding-004"
        )
        
        # Cache des r√©sum√©s de livres
        self.summaries = {}
        self.summaries_file = Path("data/book_summaries.json")
        self._load_summaries()
        
        # Statut d'initialisation
        self.initialized_books = set()
        
    def _load_summaries(self):
        """Charge les r√©sum√©s de livres depuis le cache"""
        if self.summaries_file.exists():
            try:
                with open(self.summaries_file, 'r', encoding='utf-8') as f:
                    self.summaries = json.load(f)
                print(f"üìö R√©sum√©s charg√©s pour {len(self.summaries)} livres")
            except:
                self.summaries = {}
        else:
            self.summaries = {}
    
    def _save_summaries(self):
        """Sauvegarde les r√©sum√©s de livres"""
        self.summaries_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.summaries_file, 'w', encoding='utf-8') as f:
            json.dump(self.summaries, f, ensure_ascii=False, indent=2)
    
    async def prepare_book(self, book_name: str, book_data: Dict):
        """Pr√©pare un livre pour l'IA avec chunking intelligent"""
        
        if book_name in self.initialized_books:
            print(f"üìñ {book_name} d√©j√† pr√©par√©")
            return True
        
        print(f"üîß Pr√©paration de {book_name} pour l'IA...")
        
        try:
            # Cr√©er collection ChromaDB
            collection = self.chroma_client.get_or_create_collection(
                name=f"breslov_{book_name.lower().replace(' ', '_')}",
                embedding_function=self.embedding_fn,
                metadata={"book": book_name}
            )
            
            # Chunker intelligemment
            chunks = []
            chunk_id = 0
            
            for ref, content in book_data.get('sections', {}).items():
                hebrew_text = content.get('hebrew', '')
                english_text = content.get('english', '')
                
                # Combiner h√©breu et anglais pour l'embedding
                combined_text = f"{hebrew_text}\n\n{english_text}"
                
                # Cr√©er des chunks de taille appropri√©e (max 1000 caract√®res)
                if len(combined_text) > 1000:
                    # Diviser en chunks plus petits
                    words = combined_text.split()
                    current_chunk = []
                    current_length = 0
                    
                    for word in words:
                        if current_length + len(word) > 800:  # Marge de s√©curit√©
                            if current_chunk:
                                chunk = {
                                    'id': f"{book_name}_{ref}_{chunk_id}",
                                    'text': ' '.join(current_chunk),
                                    'metadata': {
                                        'book': book_name,
                                        'ref': ref,
                                        'hebrew': hebrew_text,
                                        'english': english_text,
                                        'chunk_id': chunk_id
                                    }
                                }
                                chunks.append(chunk)
                                chunk_id += 1
                                current_chunk = []
                                current_length = 0
                        
                        current_chunk.append(word)
                        current_length += len(word) + 1
                    
                    # Dernier chunk
                    if current_chunk:
                        chunk = {
                            'id': f"{book_name}_{ref}_{chunk_id}",
                            'text': ' '.join(current_chunk),
                            'metadata': {
                                'book': book_name,
                                'ref': ref,
                                'hebrew': hebrew_text,
                                'english': english_text,
                                'chunk_id': chunk_id
                            }
                        }
                        chunks.append(chunk)
                        chunk_id += 1
                else:
                    # Chunk simple
                    chunk = {
                        'id': f"{book_name}_{ref}_{chunk_id}",
                        'text': combined_text,
                        'metadata': {
                            'book': book_name,
                            'ref': ref,
                            'hebrew': hebrew_text,
                            'english': english_text,
                            'chunk_id': chunk_id
                        }
                    }
                    chunks.append(chunk)
                    chunk_id += 1
            
            # Ajouter √† ChromaDB par batch
            if chunks:
                batch_size = 50
                for i in range(0, len(chunks), batch_size):
                    batch = chunks[i:i+batch_size]
                    collection.add(
                        documents=[c['text'] for c in batch],
                        metadatas=[c['metadata'] for c in batch],
                        ids=[c['id'] for c in batch]
                    )
                    print(f"  üì¶ Batch {i//batch_size + 1}: {len(batch)} chunks ajout√©s")
            
            # G√©n√©rer r√©sum√© ma√Ætre si pas d√©j√† fait
            if book_name not in self.summaries:
                print(f"  üìù G√©n√©ration du r√©sum√© pour {book_name}...")
                summary = await self._generate_book_summary(book_name, book_data)
                self.summaries[book_name] = summary
                self._save_summaries()
            
            self.initialized_books.add(book_name)
            print(f"‚úÖ {book_name} pr√©par√©: {len(chunks)} chunks, r√©sum√© disponible")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la pr√©paration de {book_name}: {e}")
            return False
    
    async def answer_question(self, question: str, book_context: Optional[str] = None, mode: str = "study"):
        """R√©pond aux questions avec contexte intelligent"""
        
        try:
            # D√©terminer la strat√©gie
            strategy = await self._determine_strategy(question, book_context, mode)
            
            if strategy['type'] == 'single_book':
                return await self._answer_single_book(question, strategy['book'], mode)
            elif strategy['type'] == 'multi_book':
                return await self._answer_multi_book(question, mode)
            else:
                return await self._answer_general(question, mode)
                
        except Exception as e:
            print(f"‚ùå Erreur Gemini: {e}")
            return {
                'answer': f"D√©sol√©, une erreur est survenue: {str(e)}",
                'error': True,
                'strategy': 'error'
            }
    
    async def _determine_strategy(self, question: str, book_context: Optional[str], mode: str) -> Dict:
        """D√©termine la strat√©gie de r√©ponse optimale"""
        
        # Si contexte de livre sp√©cifi√©
        if book_context:
            return {
                'type': 'single_book',
                'book': book_context
            }
        
        # Analyser la question pour d√©tecter mention de livres
        question_lower = question.lower()
        mentioned_books = []
        
        for book_name in self.summaries.keys():
            if (book_name.lower() in question_lower or 
                any(word in question_lower for word in book_name.lower().split())):
                mentioned_books.append(book_name)
        
        if len(mentioned_books) == 1:
            return {
                'type': 'single_book',
                'book': mentioned_books[0]
            }
        elif len(mentioned_books) > 1:
            return {
                'type': 'multi_book',
                'books': mentioned_books
            }
        else:
            return {
                'type': 'multi_book',  # Par d√©faut, chercher dans tous
                'books': list(self.summaries.keys())
            }
    
    async def _answer_single_book(self, question: str, book_name: str, mode: str):
        """R√©pond pour un livre sp√©cifique"""
        
        try:
            # Recherche vectorielle
            collection_name = f"breslov_{book_name.lower().replace(' ', '_')}"
            collection = self.chroma_client.get_collection(collection_name)
            
            results = collection.query(
                query_texts=[question],
                n_results=10
            )
            
            # Construire contexte
            context_parts = [
                f"üìö LIVRE: {book_name}",
                f"üéØ MODE: {mode.upper()}",
                f"R√âSUM√â: {self.summaries.get(book_name, 'N/A')}",
                "\nPASSAGES PERTINENTS:"
            ]
            
            for i, (doc, meta) in enumerate(zip(results['documents'][0], results['metadatas'][0])):
                context_parts.append(f"""
Passage {i+1} - {meta['ref']}:
H√©breu: {meta['hebrew'][:300]}...
Anglais: {meta['english'][:300]}...
---""")
            
            # Prompt sp√©cialis√© selon le mode
            prompt = self._build_prompt(mode, question, ''.join(context_parts), book_name)
            
            response = self.model.generate_content(prompt)
            
            return {
                'answer': response.text,
                'book': book_name,
                'sources_used': len(results['documents'][0]),
                'strategy': 'single_book',
                'mode': mode,
                'citations': [meta['ref'] for meta in results['metadatas'][0]]
            }
            
        except Exception as e:
            print(f"‚ùå Erreur single book: {e}")
            raise e
    
    async def _answer_multi_book(self, question: str, mode: str):
        """R√©pond en consultant plusieurs livres"""
        
        all_results = []
        
        # Chercher dans tous les livres initialis√©s
        for book_name in self.initialized_books:
            try:
                collection_name = f"breslov_{book_name.lower().replace(' ', '_')}"
                collection = self.chroma_client.get_collection(collection_name)
                results = collection.query(query_texts=[question], n_results=3)
                
                for doc, meta, distance in zip(
                    results['documents'][0], 
                    results['metadatas'][0],
                    results['distances'][0]
                ):
                    all_results.append({
                        'book': book_name,
                        'doc': doc,
                        'meta': meta,
                        'score': 1 - distance  # Convertir distance en score
                    })
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur recherche dans {book_name}: {e}")
                continue
        
        # Trier par pertinence
        all_results.sort(key=lambda x: x['score'], reverse=True)
        top_results = all_results[:15]
        
        # Grouper par livre
        by_book = {}
        for result in top_results:
            book = result['book']
            if book not in by_book:
                by_book[book] = []
            by_book[book].append(result)
        
        # Construire contexte multi-livres
        context_parts = [f"üéØ MODE: {mode.upper()}", "ANALYSE MULTI-LIVRES:\n"]
        
        for book, passages in by_book.items():
            context_parts.append(f"\nüìö {book}:")
            context_parts.append(f"R√©sum√©: {self.summaries.get(book, 'N/A')[:200]}...")
            
            for p in passages[:2]:
                context_parts.append(f"- {p['meta']['ref']}: {p['doc'][:200]}...")
        
        prompt = self._build_prompt(mode, question, ''.join(context_parts), "MULTI-LIVRES")
        
        response = self.model.generate_content(prompt)
        
        return {
            'answer': response.text,
            'books_consulted': list(by_book.keys()),
            'total_sources': len(top_results),
            'strategy': 'multi_book',
            'mode': mode,
            'citations': [r['meta']['ref'] for r in top_results[:10]]
        }
    
    async def _answer_general(self, question: str, mode: str):
        """R√©ponse g√©n√©rale bas√©e sur la connaissance de Gemini"""
        
        prompt = f"""Tu es un expert des enseignements de Rabbi Nachman de Breslev.

MODE: {mode.upper()}

QUESTION: {question}

R√©ponds selon le mode sp√©cifi√©:
- STUDY: Analyse approfondie et acad√©mique
- EXPLORATION: Conversation ouverte et exploratoire  
- ANALYSIS: Examen critique et d√©taill√©
- COUNSEL: Guidance spirituelle personnalis√©e

Utilise tes connaissances g√©n√©rales sur Rabbi Nachman et la tradition Breslov.
R√©ponds en fran√ßais, avec profondeur et authenticit√©.

R√©ponse:"""
        
        response = self.model.generate_content(prompt)
        
        return {
            'answer': response.text,
            'strategy': 'general_knowledge',
            'mode': mode,
            'sources_used': 0
        }
    
    def _build_prompt(self, mode: str, question: str, context: str, book_context: str) -> str:
        """Construit le prompt selon le mode"""
        
        base_instructions = {
            "study": "Analyse ACAD√âMIQUE approfondie avec r√©f√©rences pr√©cises. Structure claire avec sources exactes.",
            "exploration": "Conversation OUVERTE et exploratoire. Encourage questions et r√©flexions personnelles.",
            "analysis": "Examen CRITIQUE et d√©taill√©. Montre nuances, contradictions, et perspectives multiples.", 
            "counsel": "Guidance SPIRITUELLE personnalis√©e. Conseils pratiques pour l'application quotidienne."
        }
        
        instruction = base_instructions.get(mode, base_instructions["study"])
        
        return f"""Tu es un MA√éTRE expert des textes de Rabbi Nachman de Breslev.

CONTEXTE: {book_context}
{context}

QUESTION: {question}

INSTRUCTIONS CRITIQUES:
1. {instruction}
2. Base TOUTE ta r√©ponse sur les textes fournis - JAMAIS de g√©n√©ralit√©s
3. Cite EXACTEMENT avec r√©f√©rences (livre, section)
4. Fait des connexions profondes dans les textes
5. R√©ponds en fran√ßais fluide et authentique
6. Utilise le contexte h√©breu ET anglais fourni

MODE: {mode.upper()}

R√©ponse compl√®te et profonde:"""
    
    async def _generate_book_summary(self, book_name: str, book_data: Dict) -> str:
        """G√©n√®re un r√©sum√© structur√© du livre"""
        
        # Prendre √©chantillon repr√©sentatif
        sample_sections = list(book_data.get('sections', {}).items())[:10]
        sample_text = "\n\n".join([
            f"{ref}:\nH√©breu: {content['hebrew'][:500]}\nAnglais: {content['english'][:500]}" 
            for ref, content in sample_sections
        ])
        
        prompt = f"""Analyse ce livre de Rabbi Nachman '{book_name}' et cr√©e un r√©sum√© STRUCTUR√â:

√âCHANTILLON:
{sample_text[:15000]}

Cr√©e un r√©sum√© incluant:
1. TH√àMES PRINCIPAUX du livre
2. CONCEPTS CL√âS enseign√©s
3. STRUCTURE g√©n√©rale
4. ENSEIGNEMENTS PRATIQUES
5. LIENS avec autres textes Breslov

Format: Texte structur√© et concis (max 500 mots):"""
        
        try:
            response = self.flash_model.generate_content(prompt)
            return response.text
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration r√©sum√© {book_name}: {e}")
            return f"R√©sum√© non disponible pour {book_name}"